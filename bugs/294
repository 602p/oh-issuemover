{"status": "chatting", "priority": "wish", "title": "Unify the way background processing is done", "milestone": "", "superceder": "", "nosylist": ["ktarnowski, paulproteus"], "assigned": "", "waitingon": "", "keywords": [], "id": "294", "files": [], "history": [{"message": "Some pseudo-random thoughts:\n\n* it uses up RAM even when idle (and Python processes aren't cheap)\n* I don't feel particularly comfortable configuring rabbitmq, and I don't really\nlike asking people to install it on their own machines.\n* celery isn't bad in theory, but what is *definitely* bad is writing HTTP code\nthat is synchronous. It seems to have some sort of gevent thing now.\n* We were using an old-ish version of celery, but I kind of hate having to keep\nup with updates to it.\n   \n", "author": "paulproteus"}, {"message": "It would be nice to have unified mechanism for executing background tasks. \nInstead of using cron or touching a file, there should be, ideally, flexible job \nqueue running on one of OH servers.\n\nThere are several things to keep in mind:\n- The target machine runs several other services, hence there's limited memory \nand disk space for each service.\n- One service might take down the whole machine, so there's a need for the queue \nto use some sort of persistence mechanism for tasks/jobs.\n- It should be possible to set task timeout or, ideally, resource limits for each \ntask (CPU time, memory, disk space etc.).\n- It should be easy to get the queue up and running (e.g. on development \nmachine).\n- Ideally, the queue should provide pluggable interface for specifying control \npoints (e.g. HTTP access)\n- Celery is evil\n\nThis is generally a nice subject for new Open Source project, although there are \nseveral solutions available, which can serve their purpose here.\n   \n", "author": "ktarnowski"}]}