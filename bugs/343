{"status": "resolved", "priority": "feature", "title": "Dev sites should serve out robots rules that prevents them from being spidered", "milestone": "0.11.04", "superceder": "", "nosylist": ["Lorthirk, palhmbs, paulproteus"], "assigned": "paulproteus", "waitingon": "", "keywords": ["bitesize"], "id": "343", "files": [{"url": "http://openhatch.org/bugs/file226/0001-Added-ROBOTS_NO_FOLLOW.patch", "author": "palhmbs"}, {"url": "http://openhatch.org/bugs/file255/0001-Added-robots.txt-management-created-new-restrictive-.patch", "author": "Lorthirk"}], "history": [{"message": "Er, Lorthirk, you're right; the robots.txt you include totally does work\nproperly. I was mistaken.\n\nPushed and deployed!\n   \n", "author": "paulproteus"}, {"message": "Some remaining caveats:\n* The robots.txt we serve out from dev sites should be the 2-line \"Block\neverything\" robots\n* Minor minor style thing: Usually we write \"# words\" rather than \"#words\"\ni.e. we put a space in there.\nThe first one is important to succeeding at the goal of the ticket.\nThat's all I have for you! Otherwise it looks good, and the commit log message\nis quite reasonable.\n   \n", "author": "paulproteus"}, {"message": "I tried again with the patches. Hope it's ok now.\n   \n", "author": "Lorthirk"}, {"message": "Lorthirk,\n\nThese patches look good, except for one thing: They're not in \"git format-patch\"\nform. You have to make a local commit, including a commit log message, and then\ncreate a patch file from that.\n<a href=\"http://openhatch.org/wiki/How_to_generate_patches_with_git_format-patch\">http://openhatch.org/wiki/How_to_generate_patches_with_git_format-patch</a> has some\ninstructions, but it should be as easy as:\n\n* Make the commit\n* git format-patch origin/master\n\nWe like commits that are in that form because they let you leave a log message\nthat explains what you did, and also we can celebrate that you are the author of\nthe commit.\n\nSorry I took a few days to get back to you about this!\n   \n", "author": "paulproteus"}, {"message": "New restrictive robots.txt created under mysite/base/templates, and reverted the \nold one to mysite/static\n   \n", "author": "Lorthirk"}, {"message": "Removed the unnecessary comment. Are you sure about the missing robots.txt though? \nI see it in mysite/base/templates directory...\n   \n", "author": "Lorthirk"}, {"message": "Some feedback:\n\n* If you comment something out of urls.py, just delete it instead. That \nway future people who read what the code aren't distracted by abandoned \nideas.\n\n* direct_to_template looks good.\n\n* You didn't 'git add' the robots.txt file.\n\nThe patch itself looks good, but it's missing the robots.txt file, so \nit can't quite work yet. (-:\n   \n", "author": "paulproteus"}, {"message": "Ok, I moved robots.txt to templates folder. Patch is attached (I used PyCharm's Git \npatching, so if it's wrong please tell me and I'll use the method described in the \nwiki).\n   \n", "author": "Lorthirk"}, {"message": "I would say, it's okay to have the robots.txt in the templates directory. \nThe redirect strikes me as a little odd.\n\nWe should rename the static/robots.txt into static/production_robots.txt, \nand then I will adjust the rewrite rules on the server.\n   \n", "author": "paulproteus"}, {"message": "I'm going through the issue. I have only one question: according to \n<a href=\"http://fredericiana.com/2010/06/09/three-ways-to-add-a-robots-txt-to-your-django-\">http://fredericiana.com/2010/06/09/three-ways-to-add-a-robots-txt-to-your-django-</a>\nproject method 2, I should add a rule in urls.py to do a direct_to_template on \nrobots.txt HTTP request. The problem is that robots.txt is not actually in the \nmysite/base/templates folder, but it's in mysite/static, so redirect_to_template \nwon't find it. Currently I have two solutions:\n\n1- move robots.txt to mysite/base/templates, but I honestly don't like it: \ntemplates folder should hold just templates :)\n\n2- use redirect_to instead of direct_to_template. It works this way, but if I \nmanually look for <a href=\"http://localhost:8000/robots.txt\">http://localhost:8000/robots.txt</a> I get redirected to \n<a href=\"http://localhost:8000/static/robots.txt.\">http://localhost:8000/static/robots.txt.</a> Is this a problem? Will bots find the \nfile anyway?\n\nOf course, other solutions are more than welcome.\n   \n", "author": "Lorthirk"}, {"message": "Ok, because of feedback here and on IRC....\n\nI found this - <a href=\"http://fredericiana.com/2010/06/09/three-ways-to-add-a-robots-txt-\">http://fredericiana.com/2010/06/09/three-ways-to-add-a-robots-txt-</a>\nto-your-django-project/\n\nAnd everyone agrees that step 2 is the one I should follow.\n\nI'm not sure that creating a wiki to run through adding the robots.txt is \nneeded...\n\nI'll will mentor Lorthirk in adding this sometime soon I hope.\n   \n", "author": "palhmbs"}, {"message": "To clarify the whitespace issue: When I look at the patch, I see there's a \ncomment that's modified -- \"Where should the user be sent if she clicks \n'logout'?\"\n\nSince that comment whitespace change isn't related to the rest of the commit, \nit should be in a separate patch, if at all.\n   \n", "author": "paulproteus"}, {"message": "This is almost correct: Two bits of feedback:\n\n1) You seem to have performed a whitespace change in mysite/base/decorators.py\n\n2) You should do 'from django.conf import settings'. See also \n<a href=\"http://docs.djangoproject.com/en/1.2/topics/settings/\">http://docs.djangoproject.com/en/1.2/topics/settings/</a> \"Using settings in Python \ncode\"\n\n3) (Optional) I would choose a different name, like PERMIT_ROBOTS. I like when \nconfiguration variables are positive, rather than negative, so I don't end up \nconfused\n\nIt looks quite good as-is.\n\nI admit, thinking this through right now, that we could probably make it work \nby just adding a new URL to the Django app:\n\n/robots.txt\n\nand make that just serve up a very restrictive (noindex, etc.) robots.txt.\n\nThen on the deployment, I can personally configure the site to pass that \nthrough to a different robots.txt.\n\nI'm a little unhappy mentioning that because it makes it sound like the work \nyou did can be redone in a WAY simpler way, which would imply that you wasted \ntime on doing it the hard way. Especially since the bug here was about doing it \nthe hard way, and now here I am swooping in at the last minute with a new, \nsimpler design. I'd take a patch that did it either way; if you want to keep \ndoing it the settings.py way, then follow the feedback above!\n   \n", "author": "paulproteus"}, {"message": "So here it is - Files affected are: \n mysite/settings.py\n mysite/deployment_settings.py\n mysite/base/decorators.py\n and test for True or False in\n mysite/base/templates/base/base.html\n\nHopefully this resolves it, please review.\n   \n", "author": "palhmbs"}, {"message": "I discussed this with pythonian4000 and if we are right and the \nproduction_settings.py replaces  settings.py when the code is deployed, all I \nneed to do is put the GLOBAL variable into production_settings.py to turn the \nmeta robot's no follow code back off.\n\nI'll add this to the patch tomorrow.\n   \n", "author": "palhmbs"}, {"message": "Since I got stuck on this I'm setting this back to unassigned.\nPlease somebody squash this bug.\n   \n", "author": "palhmbs"}, {"message": "Added ROBOTS_NO_FOLLOW = True to mysite/settings.py\nWith help from Jack I have pulled in the data from mysite.settings to the \ndecorator.py \nAnd tested it in base.html \n\nHow might I test to disable it when it's turned off in deployment_settings.py ?\nPaul\n   \n", "author": "palhmbs"}, {"message": "Imagine for now that you had to add that &lt;META&gt; tag to all pages. Then you would\nedit mysite/base/templates/base/base.html to add it.\n\nYou'll have to surround it with some kind of \"if\", like, \"{% if no_robots %}\"\n\nYou'll also have to set a variable in settings.py that controls it (set it to\nTrue in settings.py and set it to False in deployment_settings.py).\n\nProbably this is best done with a template tag, so that you can look at the\nsettings object.\n   \n", "author": "paulproteus"}, {"message": "I'll just grab this, looks like something I ought to be able to do.\n   \n", "author": "palhmbs"}, {"message": "Right now, developer instances of the OpenHatch code show up on Google.\n\nWe can change that by optionally adding:\n\n&lt;META NAME=\"ROBOTS\" CONTENT=\"NOINDEX, NOFOLLOW\"&gt;\n\nto the HTML we generate.\n\nSee <a href=\"http://www.robotstxt.org/meta.html\">http://www.robotstxt.org/meta.html</a> for more information.\n   \n", "author": "paulproteus"}]}